{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pickle as pickle\n",
    "\n",
    "# from loc_predict.processing import _split_train_test\n",
    "from utils.utils import load_data\n",
    "from shapely import wkt\n",
    "\n",
    "import powerlaw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from metrics.metrics import radius_gyration, jump_length, location_frquency, wait_time\n",
    "\n",
    "data_dir = os.path.join(\"data\", \"validation\")\n",
    "\n",
    "def save_pk_file(save_path, data):\n",
    "    \"\"\"Function to save data to pickle format given data and path.\"\"\"\n",
    "    with open(save_path, \"wb\") as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[12.9382, 11.2081, 11.0942],\n",
    "        [12.9211, 11.1199, 11.0261],\n",
    "        [14.3441, 13.3287, 12.6234],\n",
    "        [13.7739, 13.2769, 12.5926]], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.cumsum(x / x.sum(dim=-1, keepdim=True), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.searchsorted(p, torch.rand([p.shape[0], 1]).to(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.gather(dim=1, index=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack([torch.cat([xi[:bpi], e, xi[bpi:]]) for xi, bpi in zip(x, bp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= torch.tensor([[6031, 6031, 6031, 6047],\n",
    "        [6031, 6031, 6031, 6046],\n",
    "        [6047, 6047, 6047, 6046],\n",
    "        [6046, 6046, 6046, 6012],\n",
    "        [6046, 6046, 6046, 6013],\n",
    "        [6012, 6012, 6012, 6008],\n",
    "        [6013, 6013, 6013, 6031],\n",
    "        [6008, 6008, 6008, 6031],\n",
    "        [6031, 6031, 6031, 6031],\n",
    "        [6031, 6031, 6031, 6046],\n",
    "        [   0, 6031, 6031, 6046],\n",
    "        [   0,    0, 6046,    0]], device='cuda:0')\n",
    "\n",
    "pred_loc= torch.tensor([[6031],\n",
    "        [6033],\n",
    "        [6031],\n",
    "        [6031]], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_after = torch.tensor([[6031, 6031, 6031, 6047],\n",
    "        [6031, 6031, 6031, 6046],\n",
    "        [6047, 6047, 6047, 6046],\n",
    "        [6046, 6046, 6046, 6012],\n",
    "        [6046, 6046, 6046, 6013],\n",
    "        [6012, 6012, 6012, 6008],\n",
    "        [6013, 6013, 6013, 6031],\n",
    "        [6008, 6008, 6008, 6031],\n",
    "        [6031, 6031, 6031, 6031],\n",
    "        [6031, 6031, 6031, 6046],\n",
    "        [6031, 6031, 6031, 6046],\n",
    "        [   0, 6033, 6046, 6031],\n",
    "        [   0,    0, 6031,    0]], device='cuda:0')\n",
    "x_len_before = torch.tensor([9, 10, 11, 10], device='cuda:0')\n",
    "x_len_after = torch.tensor([11, 12, 13, 12], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = torch.stack([xi[x_len_beforei:x_len_afteri] for xi, x_len_beforei, x_len_afteri in zip(x_after.transpose(1, 0), x_len_before, x_len_after)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([gen, gen], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xi, x_len_beforei, x_len_afteri in zip(x_after.transpose(1, 0), x_len_before, x_len_after):\n",
    "    print(xi, x_len_beforei, x_len_afteri)\n",
    "    print(xi[x_len_beforei:x_len_afteri])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# read and preprocess\n",
    "sp = pd.read_csv(os.path.join(data_dir, \"sp.csv\"), index_col=\"id\")\n",
    "loc = pd.read_csv(os.path.join(data_dir, \"locs_s2.csv\"), index_col=\"id\")\n",
    "sp = load_data(sp, loc)\n",
    "\n",
    "train_data, vali_data, test_data = _split_train_test(sp)\n",
    "\n",
    "test_data = test_data.merge(\n",
    "    loc.reset_index()[[\"id\", \"center\"]].rename(columns={\"id\": \"location_id\"}), how=\"left\", on=\"location_id\"\n",
    ")\n",
    "test_data.rename(columns={\"center\": \"geometry\"}, inplace=True)\n",
    "test_data[\"geometry\"] = test_data[\"geometry\"].apply(wkt.loads)\n",
    "test_data = gpd.GeoDataFrame(test_data, geometry=\"geometry\", crs=\"EPSG:4326\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = jump_length(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabel = \"$\\Delta r\\,(m)$\"\n",
    "ylabel = \"$P(\\Delta r)$\"\n",
    "xmin = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = metric[metric>xmin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit power law\n",
    "fit = powerlaw.Fit(metric, xmin=xmin)\n",
    "\n",
    "# plotting\n",
    "powerlaw.plot_pdf(metric, label=\"data\")\n",
    "fit.power_law.plot_pdf(linestyle=\"--\", label=\"powerlaw fit\")\n",
    "fit.truncated_power_law.plot_pdf(linestyle=\"--\", label=\"truncated power law\")\n",
    "fit.lognormal.plot_pdf(linestyle=\"--\", label=\"lognormal fit\")\n",
    "\n",
    "plt.legend(prop={\"size\": 13})\n",
    "plt.xlabel(xlabel, fontsize=16)\n",
    "plt.ylabel(ylabel, fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_sp = pd.read_csv(os.path.join(data_dir, \"mobis_mhsa_generation.csv\"))\n",
    "simulated_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_sp = simulated_sp.merge(\n",
    "    loc.reset_index()[[\"id\", \"center\"]].rename(columns={\"id\": \"location_id\"}), how=\"left\", left_on=\"generated_ls\", right_on=\"location_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_sp.rename(columns={\"center\": \"geometry\"}, inplace=True)\n",
    "simulated_sp[\"geometry\"] = simulated_sp[\"geometry\"].apply(wkt.loads)\n",
    "simulated_sp = gpd.GeoDataFrame(simulated_sp, geometry=\"geometry\", crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_sp.drop(columns={\"user_id\", \"generated_ls\"}, inplace=True)\n",
    "simulated_sp.rename(columns={\"seq_id\": \"user_id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated_jl = jump_length(simulated_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabel = \"$\\Delta r\\,(m)$\"\n",
    "ylabel = \"$P(\\Delta r)$\"\n",
    "xmin = 1\n",
    "simulated_jl = simulated_jl[simulated_jl>xmin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit power law\n",
    "# fit = powerlaw.Fit(simulated_jl, xmin=xmin)\n",
    "\n",
    "# plotting\n",
    "powerlaw.plot_pdf(metric, label=\"data\")\n",
    "powerlaw.plot_pdf(simulated_jl, label=\"simulated\")\n",
    "\n",
    "# fit.power_law.plot_pdf(linestyle=\"--\", label=\"powerlaw fit\")\n",
    "# fit.truncated_power_law.plot_pdf(linestyle=\"--\", label=\"truncated power law\")\n",
    "# fit.lognormal.plot_pdf(linestyle=\"--\", label=\"lognormal fit\")\n",
    "\n",
    "plt.legend(prop={\"size\": 13})\n",
    "plt.xlabel(xlabel, fontsize=16)\n",
    "plt.ylabel(ylabel, fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = pd.read_csv(os.path.join(data_dir, \"sp.csv\"), index_col=\"id\")\n",
    "# loc = pd.read_csv(os.path.join(data_dir, \"locs_s2.csv\"), index_col=\"id\")\n",
    "# sp = load_data(sp, loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_user = np.random.choice(sp[\"user_id\"].unique(), 100, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.loc[sp[\"user_id\"].isin(selected_user)].to_csv(\"./data/sp_small.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate pairwise distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from trackintel.geogr.distances import calculate_distance_matrix\n",
    "import pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_locs = pd.read_csv(\"./data/all_locations.csv\", index_col=\"id\")\n",
    "all_locs[\"geometry\"] = all_locs[\"geometry\"].apply(wkt.loads)\n",
    "all_locs = gpd.GeoDataFrame(all_locs, geometry=\"geometry\", crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder(dtype=np.int64, handle_unknown=\"use_encoded_value\", unknown_value=-1).fit(\n",
    "    all_locs[\"loc_id\"].values.reshape(-1, 1)\n",
    ")\n",
    "# add 1 to account for 0 padding\n",
    "all_locs[\"loc_id\"] = enc.transform(all_locs[\"loc_id\"].values.reshape(-1, 1)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# calculate_distance_matrix(all_locs, all_locs[:256], dist_metric=\"haversine\", n_jobs=-1)\n",
    "dist_matrix = calculate_distance_matrix(all_locs, dist_metric=\"haversine\", n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_pk_file(\"./data/temp/dist_matrix.pk\", dist_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate empirical matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loc_predict.models.markov import markov_transition_prob\n",
    "from utils.utils import load_data\n",
    "from utils.dataloader import get_train_test\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = pd.read_csv(os.path.join(\".\", \"data\", \"sp.csv\"), index_col=\"id\")\n",
    "loc = pd.read_csv(os.path.join(\".\", \"data\", \"locs_s2.csv\"), index_col=\"id\")\n",
    "sp = load_data(sp, loc)\n",
    "\n",
    "all_locs = pd.read_csv(os.path.join(\".\", \"data\", \"all_locations.csv\"), index_col=\"id\")\n",
    "all_locs[\"geometry\"] = all_locs[\"geometry\"].apply(wkt.loads)\n",
    "all_locs = gpd.GeoDataFrame(all_locs, geometry=\"geometry\", crs=\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, vali_data, test_data, all_locs = get_train_test(sp, all_locs=all_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transit_df = train_data.groupby(\"user_id\").apply(markov_transition_prob, n=1).reset_index().drop(columns=\"level_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_matrix = np.zeros((len(all_locs), len(all_locs)))\n",
    "\n",
    "for pair in tqdm(transit_df[[\"loc_1\", \"toLoc\"]].values):\n",
    "    emp_matrix[pair[0], pair[1]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pk_file(\"./data/temp/emp_matrix.pk\", emp_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check metric calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics.evaluations import Metric\n",
    "from utils.utils import load_data, setup_seed, load_config, init_save_path\n",
    "from easydict import EasyDict as edict\n",
    "from utils.dataloader import get_train_test, _get_valid_sequence\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely import wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "config = load_config(\"./config/movesim.yml\")\n",
    "config = edict(config)\n",
    "\n",
    "# read and preprocess\n",
    "sp = pd.read_csv(os.path.join(config.temp_save_root, \"sp.csv\"), index_col=\"id\")\n",
    "loc = pd.read_csv(os.path.join(config.temp_save_root, \"locs_s2.csv\"), index_col=\"id\")\n",
    "sp = load_data(sp, loc)\n",
    "\n",
    "all_locs = pd.read_csv(os.path.join(config.temp_save_root, \"all_locations.csv\"), index_col=\"id\")\n",
    "all_locs[\"geometry\"] = all_locs[\"geometry\"].apply(wkt.loads)\n",
    "all_locs = gpd.GeoDataFrame(all_locs, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "# transform to projected coordinate systems\n",
    "all_locs = all_locs.to_crs(\"EPSG:2056\")\n",
    "\n",
    "train_data, vali_data, test_data, all_locs = get_train_test(sp, all_locs=all_locs)\n",
    "\n",
    "config[\"total_loc_num\"] = int(all_locs.loc_id.max() + 1)\n",
    "config[\"total_user_num\"] = int(train_data.user_id.max() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"id\"] = np.arange(len(train_data))\n",
    "vali_data[\"id\"] = np.arange(len(vali_data))\n",
    "test_data[\"id\"] = np.arange(len(test_data))\n",
    "\n",
    "train_idx = _get_valid_sequence(train_data, print_progress=config.verbose, previous_day=config.previous_day)\n",
    "vali_idx = _get_valid_sequence(vali_data, print_progress=config.verbose, previous_day=config.previous_day)\n",
    "test_idx = _get_valid_sequence(test_data, print_progress=config.verbose, previous_day=config.previous_day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = Metric(config, locations=all_locs, input_data=vali_data, valid_start_end_idx=vali_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = [train_data.iloc[idx[0] : idx[1]][\"location_id\"].values for idx in train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = [test_data.iloc[idx[0] : idx[1]][\"location_id\"].values for idx in test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsds = metrics.get_individual_jsds(gene_data=test_seq)\n",
    "print(\n",
    "    \"Metric: distance {:.3f}, rg {:.3f}, period {:.3f}, topk all {:.3f}, topk {:.3f}\".format(\n",
    "        jsds[0], jsds[1], jsds[2], jsds[3], jsds[4]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsds = metrics.get_individual_jsds(gene_data=train_seq)\n",
    "print(\n",
    "    \"Metric: distance {:.3f}, rg {:.3f}, period {:.3f}, topk all {:.3f}, topk {:.3f}\".format(\n",
    "        jsds[0], jsds[1], jsds[2], jsds[3], jsds[4]\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.17 ('generation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "659ffd3ea00dbbc52f857660b8dafea05f804bc55dd91047cefb31e38b5505f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
