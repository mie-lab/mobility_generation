{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T21:30:59.280179Z",
     "iopub.status.busy": "2024-03-18T21:30:59.280179Z",
     "iopub.status.idle": "2024-03-18T21:31:02.825459Z",
     "shell.execute_reply": "2024-03-18T21:31:02.825459Z",
     "shell.execute_reply.started": "2024-03-18T21:30:59.280179Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pickle as pickle\n",
    "\n",
    "import shapely\n",
    "from shapely import wkt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import trackintel as ti\n",
    "from trackintel.geogr.distances import calculate_distance_matrix\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T21:31:02.827454Z",
     "iopub.status.busy": "2024-03-18T21:31:02.827454Z",
     "iopub.status.idle": "2024-03-18T21:31:02.840925Z",
     "shell.execute_reply": "2024-03-18T21:31:02.840925Z",
     "shell.execute_reply.started": "2024-03-18T21:31:02.827454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ti.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T21:31:02.842425Z",
     "iopub.status.busy": "2024-03-18T21:31:02.842425Z",
     "iopub.status.idle": "2024-03-18T21:31:02.886877Z",
     "shell.execute_reply": "2024-03-18T21:31:02.886877Z",
     "shell.execute_reply.started": "2024-03-18T21:31:02.842425Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "from loc_predict.models.markov import markov_transition_prob\n",
    "from utils.utils import load_data\n",
    "\n",
    "def save_pk_file(save_path, data):\n",
    "    \"\"\"Function to save data to pickle format given data and path.\"\"\"\n",
    "    with open(save_path, \"wb\") as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_min_days = 7 * 2\n",
    "src_max_days = 7 * 3\n",
    "\n",
    "tgt_min_days = 7 * 1\n",
    "tgt_max_days = 7 * 2\n",
    "\n",
    "type = \"small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = pd.read_csv(os.path.join(f\"../data/sp_{type}.csv\"), index_col=\"id\")\n",
    "loc = pd.read_csv(os.path.join(\"../data/loc_s2_level10_13.csv\"), index_col=\"id\")\n",
    "\n",
    "sp = load_data(sp, loc)\n",
    "\n",
    "# get all possible locations\n",
    "all_locs = pd.read_csv(\"../data/s2_loc_visited_level10_13.csv\", index_col=\"id\")\n",
    "all_locs[\"geometry\"] = all_locs[\"geometry\"].apply(wkt.loads)\n",
    "all_locs = gpd.GeoDataFrame(all_locs, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "# transform to projected coordinate systems\n",
    "all_locs = all_locs.to_crs(\"EPSG:2056\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(sp, all_locs):\n",
    "    sp.sort_values(by=[\"user_id\", \"start_day\", \"start_min\"], inplace=True)\n",
    "    sp.drop(columns={\"started_at\", \"finished_at\"}, inplace=True)\n",
    "\n",
    "    # encoder user, 0 reserved for padding\n",
    "    enc = OrdinalEncoder(dtype=np.int64)\n",
    "    sp[\"user_id\"] = enc.fit_transform(sp[\"user_id\"].values.reshape(-1, 1)) + 1\n",
    "\n",
    "    # truncate too long duration, >2 days to 2 days\n",
    "    sp.loc[sp[\"act_duration\"] > 60 * 24 * 2 - 1, \"act_duration\"] = 60 * 24 * 2 - 1\n",
    "\n",
    "    # split the datasets, user dependent 0.6, 0.2, 0.2\n",
    "    train_data, vali_data, test_data = _split_dataset(sp)\n",
    "\n",
    "    # encode unseen locations in validation and test into 0\n",
    "    enc = OrdinalEncoder(dtype=np.int64, handle_unknown=\"use_encoded_value\", unknown_value=-1).fit(\n",
    "        all_locs[\"loc_id\"].values.reshape(-1, 1)\n",
    "    )\n",
    "    # add 2 to account for 0 padding and seperation (1)\n",
    "    all_locs[\"loc_id\"] = enc.transform(all_locs[\"loc_id\"].values.reshape(-1, 1)) + 2\n",
    "\n",
    "    train_data[\"location_id\"] = enc.transform(train_data[\"location_id\"].values.reshape(-1, 1)) + 2\n",
    "    vali_data[\"location_id\"] = enc.transform(vali_data[\"location_id\"].values.reshape(-1, 1)) + 2\n",
    "    test_data[\"location_id\"] = enc.transform(test_data[\"location_id\"].values.reshape(-1, 1)) + 2\n",
    "\n",
    "    return train_data, vali_data, test_data, all_locs\n",
    "\n",
    "\n",
    "def _split_dataset(totalData):\n",
    "    \"\"\"Split dataset into train, vali and test.\"\"\"\n",
    "\n",
    "    def getSplitDaysUser(df):\n",
    "        \"\"\"Split the dataset according to the tracked day of each user.\"\"\"\n",
    "        maxDay = df[\"start_day\"].max()\n",
    "        train_split = maxDay * 0.6\n",
    "        vali_split = maxDay * 0.8\n",
    "\n",
    "        df[\"Dataset\"] = \"test\"\n",
    "        df.loc[df[\"start_day\"] < train_split, \"Dataset\"] = \"train\"\n",
    "        df.loc[\n",
    "            (df[\"start_day\"] >= train_split) & (df[\"start_day\"] < vali_split),\n",
    "            \"Dataset\",\n",
    "        ] = \"vali\"\n",
    "\n",
    "        return df\n",
    "\n",
    "    totalData = totalData.groupby(\"user_id\", group_keys=False).apply(getSplitDaysUser)\n",
    "\n",
    "    train_data = totalData.loc[totalData[\"Dataset\"] == \"train\"].copy()\n",
    "    vali_data = totalData.loc[totalData[\"Dataset\"] == \"vali\"].copy()\n",
    "    test_data = totalData.loc[totalData[\"Dataset\"] == \"test\"].copy()\n",
    "\n",
    "    # final cleaning\n",
    "    train_data.drop(columns={\"Dataset\"}, inplace=True)\n",
    "    vali_data.drop(columns={\"Dataset\"}, inplace=True)\n",
    "    test_data.drop(columns={\"Dataset\"}, inplace=True)\n",
    "\n",
    "    return train_data, vali_data, test_data\n",
    "\n",
    "train_data, vali_data, test_data, all_locs = get_train_test(sp, all_locs=all_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"id\"] = np.arange(len(train_data))\n",
    "vali_data[\"id\"] = np.arange(len(vali_data))\n",
    "test_data[\"id\"] = np.arange(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Max loc id 14882, min loc id 2, unique loc id:14881'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Max loc id {all_locs.loc_id.max()}, min loc id {all_locs.loc_id.min()}, unique loc id:{all_locs.loc_id.unique().shape[0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValidSequenceUser(df):\n",
    "\n",
    "    data_ls = []\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    min_days = df[\"start_day\"].min()\n",
    "    df[\"diff_day\"] = df[\"start_day\"] - min_days\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # exclude the first records\n",
    "        if row[\"diff_day\"] < src_min_days:\n",
    "            continue\n",
    "\n",
    "        src_trace = df.iloc[: index + 1]\n",
    "        src_trace = src_trace.loc[(src_trace[\"start_day\"] >= (row[\"start_day\"] - src_max_days))]\n",
    "\n",
    "        tgt_trace = df.iloc[index + 1: ]\n",
    "        tgt_trace = tgt_trace.loc[(tgt_trace[\"start_day\"] <= (row[\"start_day\"] + tgt_max_days))]\n",
    "\n",
    "        if ((tgt_trace[\"start_day\"].max() - tgt_trace[\"start_day\"].min()) < tgt_min_days) or len(tgt_trace) == 0:\n",
    "            continue\n",
    "\n",
    "        curr_dict = {}\n",
    "        curr_dict[\"src\"] = src_trace[\"location_id\"].values\n",
    "        curr_dict[\"src_duration\"] = src_trace[\"act_duration\"].values.astype(int)\n",
    "        curr_dict[\"src_user\"] = src_trace[\"user_id\"].values[0]\n",
    "        curr_dict[\"src_weekday\"] = src_trace[\"weekday\"].values\n",
    "        curr_dict[\"src_startmin\"] = src_trace[\"start_min\"].values\n",
    "\n",
    "\n",
    "        curr_dict[\"tgt\"] = tgt_trace[\"location_id\"].values\n",
    "        curr_dict[\"tgt_duration\"] = tgt_trace[\"act_duration\"].values.astype(int)\n",
    "        curr_dict[\"tgt_weekday\"] = tgt_trace[\"weekday\"].values\n",
    "        curr_dict[\"tgt_startmin\"] = tgt_trace[\"start_min\"].values\n",
    "\n",
    "        data_ls.append(curr_dict)\n",
    "\n",
    "    return data_ls\n",
    "\n",
    "def applyParallel(dfGrouped, func, n_jobs, print_progress=True, **kwargs):\n",
    "    return Parallel(n_jobs=n_jobs)(\n",
    "        delayed(func)(group, **kwargs) for _, group in tqdm(dfGrouped, disable=not print_progress)\n",
    "    )\n",
    "\n",
    "def get_valid_data(df):\n",
    "    valid_data = applyParallel(df.groupby(\"user_id\"),getValidSequenceUser, n_jobs=-1)\n",
    "    return [item for sublist in valid_data for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:17<00:00, 29.04it/s]\n",
      "100%|██████████| 498/498 [00:02<00:00, 218.07it/s] \n",
      "100%|██████████| 500/500 [00:02<00:00, 197.92it/s] \n"
     ]
    }
   ],
   "source": [
    "valid_train_data = get_valid_data(train_data)\n",
    "valid_validation_data = get_valid_data(vali_data)\n",
    "valid_test_data = get_valid_data(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125954, 28603, 29971)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_train_data), len(valid_validation_data), len(valid_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 156), (215, 160), (211, 132))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_max_len(ls):\n",
    "\n",
    "    max_src_len = 0\n",
    "    max_tgt_len = 0\n",
    "    for seq in ls:\n",
    "        seq_len = len(seq[\"src\"])\n",
    "        tgt_len = len(seq[\"tgt\"])\n",
    "\n",
    "        if seq_len > max_src_len:\n",
    "            max_src_len = seq_len\n",
    "        if tgt_len > max_tgt_len:\n",
    "            max_tgt_len = tgt_len\n",
    "\n",
    "    return max_src_len, max_tgt_len\n",
    "\n",
    "get_max_len(valid_train_data), get_max_len(valid_validation_data), get_max_len(valid_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pk_file(os.path.join(\"..\", \"data\", \"diff\", f\"train_level10_13_{src_min_days}_{tgt_min_days}_{type}.pk\"), valid_train_data)\n",
    "\n",
    "save_pk_file(os.path.join(\"..\", \"data\", \"diff\", f\"valid_level10_13_{src_min_days}_{tgt_min_days}_{type}.pk\"), valid_validation_data)\n",
    "\n",
    "save_pk_file(os.path.join(\"..\", \"data\", \"diff\", f\"test_level10_13_{src_min_days}_{tgt_min_days}_{type}.pk\"), valid_test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For test reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'src': array([10700, 10700, 10516, 10516, 10516, 10700, 11214, 10700, 10700,\n",
       "        10516, 10700, 10516, 10700, 10700, 10700, 10516, 10700, 11208,\n",
       "        10516, 11208, 10516, 10517, 10700, 10516, 10700, 10516, 10700,\n",
       "        10700, 10516], dtype=int64),\n",
       " 'src_duration': array([ 692,   74,   69,  100,   39,  517,  665, 2324,  455,  626,  823,\n",
       "         599, 2603,  216,  891,  624,  215,  548,  603,  837,  411,  169,\n",
       "         918,  616,  811,  626,  910, 1436,  680]),\n",
       " 'src_user': 1,\n",
       " 'src_weekday': array([3, 4, 4, 4, 4, 4, 4, 5, 6, 0, 0, 1, 1, 3, 3, 4, 4, 4, 5, 5, 6, 6,\n",
       "        6, 0, 0, 1, 1, 2, 3]),\n",
       " 'src_startmin': array([1147,  411,  519,  563,  647,  728, 1224,  448, 1329,  400, 1016,\n",
       "         403, 1016,  817, 1184,  402, 1017, 1189,  324,  920,  319,  693,\n",
       "         924,  403, 1015,  405, 1015,  757,  525]),\n",
       " 'tgt': array([10700, 10516, 10686, 10700, 11208, 10700, 10516, 10516, 10700,\n",
       "        10700, 12615, 10700, 10516, 10516, 10700, 10516, 10700, 11208,\n",
       "        10516, 11541, 11208, 10516, 10681, 10700, 10516, 10700, 10700,\n",
       "        10700, 11208, 11208, 11208, 10700, 10700, 11318, 10700, 10516,\n",
       "        10700, 11208], dtype=int64),\n",
       " 'tgt_duration': array([ 784,  653,   89, 1373, 1307,  835,  501,  212, 1057, 1051,  251,\n",
       "        1256,  435,  266,  617,  678,  226,  537,  600,  170,  729,  597,\n",
       "         269,  730,  663,  876,  184,  497,  656,  100,  154,   46,  162,\n",
       "         197,  558,  737,  200,  504]),\n",
       " 'tgt_weekday': array([3, 4, 4, 4, 5, 6, 0, 0, 0, 1, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6,\n",
       "        6, 6, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3]),\n",
       " 'tgt_startmin': array([1151,  522, 1156, 1198, 1155, 1089,  465,  890, 1165,  814,  417,\n",
       "         644,  472,  835, 1151,  342, 1014, 1204,  325,  919, 1069,  385,\n",
       "         966, 1213,  541, 1206,  687,  864, 1296,  498,  639,  771,  897,\n",
       "        1028, 1251,  339, 1078, 1237])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded = pickle.load(open(os.path.join(\"..\", \"data\", \"diff\", f\"train_level10_13_{src_min_days}_{tgt_min_days}_tiny.pk\"), \"rb\"))\n",
    "loaded[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairwise distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T21:09:13.157321Z",
     "iopub.status.busy": "2024-03-18T21:09:13.156324Z",
     "iopub.status.idle": "2024-03-18T21:09:13.439965Z",
     "shell.execute_reply": "2024-03-18T21:09:13.439965Z",
     "shell.execute_reply.started": "2024-03-18T21:09:13.156324Z"
    }
   },
   "outputs": [],
   "source": [
    "visited_locs = pd.read_csv(\"../data/s2_loc_visited_level10_13.csv\", index_col=\"id\").sort_values(by=\"loc_id\")\n",
    "visited_locs[\"geometry\"] = visited_locs[\"geometry\"].apply(wkt.loads)\n",
    "visited_locs = gpd.GeoDataFrame(visited_locs, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "\n",
    "visited_locs = visited_locs.to_crs(\"EPSG:2056\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T21:09:14.671015Z",
     "iopub.status.busy": "2024-03-18T21:09:14.671015Z",
     "iopub.status.idle": "2024-03-18T21:09:14.690172Z",
     "shell.execute_reply": "2024-03-18T21:09:14.689173Z",
     "shell.execute_reply.started": "2024-03-18T21:09:14.671015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc_id</th>\n",
       "      <th>level</th>\n",
       "      <th>geometry</th>\n",
       "      <th>freq</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5152981090339651584</td>\n",
       "      <td>10</td>\n",
       "      <td>POINT (2824875.045 1159436.528)</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((10.405097146225662 46.50637570678295...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5152984577853095936</td>\n",
       "      <td>13</td>\n",
       "      <td>POINT (2822437.857 1167754.527)</td>\n",
       "      <td>38</td>\n",
       "      <td>POLYGON ((10.347820052132302 46.61871685680636...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5152985265047863296</td>\n",
       "      <td>13</td>\n",
       "      <td>POINT (2815796.126 1167304.569)</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((10.260953592346382 46.61685460820135...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5152985299407601664</td>\n",
       "      <td>13</td>\n",
       "      <td>POINT (2816020.303 1168362.492)</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((10.264376293749178 46.62629143145975...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5152985505566031872</td>\n",
       "      <td>13</td>\n",
       "      <td>POINT (2818994.419 1169160.037)</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((10.303565033130825 46.63249007077394...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 loc_id  level                         geometry  freq  \\\n",
       "id                                                                      \n",
       "0   5152981090339651584     10  POINT (2824875.045 1159436.528)     1   \n",
       "1   5152984577853095936     13  POINT (2822437.857 1167754.527)    38   \n",
       "2   5152985265047863296     13  POINT (2815796.126 1167304.569)     1   \n",
       "3   5152985299407601664     13  POINT (2816020.303 1168362.492)     1   \n",
       "4   5152985505566031872     13  POINT (2818994.419 1169160.037)     1   \n",
       "\n",
       "                                                 area  \n",
       "id                                                     \n",
       "0   POLYGON ((10.405097146225662 46.50637570678295...  \n",
       "1   POLYGON ((10.347820052132302 46.61871685680636...  \n",
       "2   POLYGON ((10.260953592346382 46.61685460820135...  \n",
       "3   POLYGON ((10.264376293749178 46.62629143145975...  \n",
       "4   POLYGON ((10.303565033130825 46.63249007077394...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visited_locs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T21:09:28.151178Z",
     "iopub.status.busy": "2024-03-18T21:09:28.151178Z",
     "iopub.status.idle": "2024-03-18T21:09:29.807341Z",
     "shell.execute_reply": "2024-03-18T21:09:29.807341Z",
     "shell.execute_reply.started": "2024-03-18T21:09:28.151178Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_distance_matrix(X):\n",
    "    X = shapely.get_coordinates(X.geometry)\n",
    "\n",
    "    distance = pdist(X, 'euclidean')\n",
    "    dist_matrix = squareform(distance)\n",
    "    return dist_matrix\n",
    "    \n",
    "dist_matrix = calculate_distance_matrix(visited_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T21:09:30.754344Z",
     "iopub.status.busy": "2024-03-18T21:09:30.753345Z",
     "iopub.status.idle": "2024-03-18T21:09:30.759833Z",
     "shell.execute_reply": "2024-03-18T21:09:30.759833Z",
     "shell.execute_reply.started": "2024-03-18T21:09:30.754344Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14881, 14881)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T21:09:39.889545Z",
     "iopub.status.busy": "2024-03-18T21:09:39.889545Z",
     "iopub.status.idle": "2024-03-18T21:09:49.131245Z",
     "shell.execute_reply": "2024-03-18T21:09:49.131245Z",
     "shell.execute_reply.started": "2024-03-18T21:09:39.889545Z"
    }
   },
   "outputs": [],
   "source": [
    "save_pk_file(\"../data/matrix/distance_13.pk\", dist_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "659ffd3ea00dbbc52f857660b8dafea05f804bc55dd91047cefb31e38b5505f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
